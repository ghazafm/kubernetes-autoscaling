{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922b3941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure working directory is the notebook's location\n",
    "NOTEBOOK_DIR = os.path.dirname(os.path.abspath(\"lab.ipynb\"))\n",
    "os.chdir(NOTEBOOK_DIR)\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f25a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCRIPT_DIR = (\n",
    "    os.path.dirname(os.path.abspath(__file__)) if \"__file__\" in globals() else os.getcwd()\n",
    ")\n",
    "PROJECT_ROOT = os.path.dirname(SCRIPT_DIR)\n",
    "DATA_DIR = os.path.join(PROJECT_ROOT, \"data\")\n",
    "CHARTS_DIR = os.path.join(SCRIPT_DIR, \"charts\")\n",
    "\n",
    "METRICS = [\n",
    "    (\"../test_3_0/pod_10\", \"response_time\", \"Response Time (ms)\", 10, 0, 3),\n",
    "    (\"../test_3_0/pod_10\", \"replica\", \"Replica Count\", 10, 0, 3),\n",
    "    (\"../test_3_0/pod_10\", \"cpu\", \"CPU Usage\", 10, 0, 3),\n",
    "    (\"../test_3_0/pod_10\", \"memory\", \"Memory Usage\", 10, 0, 3),\n",
    "    (\"../test_3_0/pod_20\", \"response_time\", \"Response Time (ms)\", 20, 0, 3),\n",
    "    (\"../test_3_0/pod_20\", \"replica\", \"Replica Count\", 20, 0, 3),\n",
    "    (\"../test_3_0/pod_20\", \"cpu\", \"CPU Usage\", 20, 0, 3),\n",
    "    (\"../test_3_0/pod_20\", \"memory\", \"Memory Usage\", 20, 0, 3),\n",
    "\n",
    "    (\"../test_3_30/pod_10\", \"response_time\", \"Response Time (ms)\", 10, 30, 3),\n",
    "    (\"../test_3_30/pod_10\", \"replica\", \"Replica Count\", 10, 30, 3),\n",
    "    (\"../test_3_30/pod_10\", \"cpu\", \"CPU Usage\", 10, 30, 3),\n",
    "    (\"../test_3_30/pod_10\", \"memory\", \"Memory Usage\", 10, 30, 3),\n",
    "    (\"../test_3_30/pod_20\", \"response_time\", \"Response Time (ms)\", 20, 30, 3),\n",
    "    (\"../test_3_30/pod_20\", \"replica\", \"Replica Count\", 20, 30, 3),\n",
    "    (\"../test_3_30/pod_20\", \"cpu\", \"CPU Usage\", 20, 30, 3),\n",
    "    (\"../test_3_30/pod_20\", \"memory\", \"Memory Usage\", 20, 30, 3),\n",
    "\n",
    "    (\"../test_3_50/pod_10\", \"response_time\", \"Response Time (ms)\", 10, 50, 3),\n",
    "    (\"../test_3_50/pod_10\", \"replica\", \"Replica Count\", 10, 50, 3),\n",
    "    (\"../test_3_50/pod_10\", \"cpu\", \"CPU Usage\", 10, 50, 3),\n",
    "    (\"../test_3_50/pod_10\", \"memory\", \"Memory Usage\", 10, 50, 3),\n",
    "    (\"../test_3_50/pod_20\", \"response_time\", \"Response Time (ms)\", 20, 50, 3),\n",
    "    (\"../test_3_50/pod_20\", \"replica\", \"Replica Count\", 20, 50, 3),\n",
    "    (\"../test_3_50/pod_20\", \"cpu\", \"CPU Usage\", 20, 50, 3),\n",
    "    (\"../test_3_50/pod_20\", \"memory\", \"Memory Usage\", 20, 50, 3),\n",
    "\n",
    "    (\"../test_3_75/pod_10\", \"response_time\", \"Response Time (ms)\", 10, 75, 3),\n",
    "    (\"../test_3_75/pod_10\", \"replica\", \"Replica Count\", 10, 75, 3),\n",
    "    (\"../test_3_75/pod_10\", \"cpu\", \"CPU Usage\", 10, 75, 3),\n",
    "    (\"../test_3_75/pod_10\", \"memory\", \"Memory Usage\", 10, 75, 3),\n",
    "    (\"../test_3_75/pod_20\", \"response_time\", \"Response Time (ms)\", 20, 75, 3),\n",
    "    (\"../test_3_75/pod_20\", \"replica\", \"Replica Count\", 20, 75, 3),\n",
    "    (\"../test_3_75/pod_20\", \"cpu\", \"CPU Usage\", 20, 75, 3),\n",
    "    (\"../test_3_75/pod_20\", \"memory\", \"Memory Usage\", 20, 75, 3),\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "\n",
    "    (\"../test_0_0/pod_10\", \"response_time\", \"Response Time (ms)\", 10, 0, 0),\n",
    "    (\"../test_0_0/pod_10\", \"replica\", \"Replica Count\", 10, 0, 0),\n",
    "    (\"../test_0_0/pod_10\", \"cpu\", \"CPU Usage\", 10, 0, 0),\n",
    "    (\"../test_0_0/pod_10\", \"memory\", \"Memory Usage\", 10, 0, 0),\n",
    "    (\"../test_0_0/pod_20\", \"response_time\", \"Response Time (ms)\", 20, 0, 0),\n",
    "    (\"../test_0_0/pod_20\", \"replica\", \"Replica Count\", 20, 0, 0),\n",
    "    (\"../test_0_0/pod_20\", \"cpu\", \"CPU Usage\", 20, 0, 0),\n",
    "    (\"../test_0_0/pod_20\", \"memory\", \"Memory Usage\", 20, 0, 0),\n",
    "\n",
    "    (\"../test_0_30/pod_10\", \"response_time\", \"Response Time (ms)\", 10, 30, 0),\n",
    "    (\"../test_0_30/pod_10\", \"replica\", \"Replica Count\", 10, 30, 0),\n",
    "    (\"../test_0_30/pod_10\", \"cpu\", \"CPU Usage\", 10, 30, 0),\n",
    "    (\"../test_0_30/pod_10\", \"memory\", \"Memory Usage\", 10, 30, 0),\n",
    "    (\"../test_0_30/pod_20\", \"response_time\", \"Response Time (ms)\", 20, 30, 0),\n",
    "    (\"../test_0_30/pod_20\", \"replica\", \"Replica Count\", 20, 30, 0),\n",
    "    (\"../test_0_30/pod_20\", \"cpu\", \"CPU Usage\", 20, 30, 0),\n",
    "    (\"../test_0_30/pod_20\", \"memory\", \"Memory Usage\", 20, 30, 0),\n",
    "\n",
    "    (\"../test_0_50/pod_10\", \"response_time\", \"Response Time (ms)\", 10, 50, 0),\n",
    "    (\"../test_0_50/pod_10\", \"replica\", \"Replica Count\", 10, 50, 0),\n",
    "    (\"../test_0_50/pod_10\", \"cpu\", \"CPU Usage\", 10, 50, 0),\n",
    "    (\"../test_0_50/pod_10\", \"memory\", \"Memory Usage\", 10, 50, 0),\n",
    "    (\"../test_0_50/pod_20\", \"response_time\", \"Response Time (ms)\", 20, 50, 0),\n",
    "    (\"../test_0_50/pod_20\", \"replica\", \"Replica Count\", 20, 50, 0),\n",
    "    (\"../test_0_50/pod_20\", \"cpu\", \"CPU Usage\", 20, 50, 0),\n",
    "    (\"../test_0_50/pod_20\", \"memory\", \"Memory Usage\", 20, 50, 0),\n",
    "\n",
    "    (\"../test_0_75/pod_10\", \"response_time\", \"Response Time (ms)\", 10, 75, 0),\n",
    "    (\"../test_0_75/pod_10\", \"replica\", \"Replica Count\", 10, 75, 0),\n",
    "    (\"../test_0_75/pod_10\", \"cpu\", \"CPU Usage\", 10, 75, 0),\n",
    "    (\"../test_0_75/pod_10\", \"memory\", \"Memory Usage\", 10, 75, 0),\n",
    "    (\"../test_0_75/pod_20\", \"response_time\", \"Response Time (ms)\", 20, 75, 0),\n",
    "    (\"../test_0_75/pod_20\", \"replica\", \"Replica Count\", 20, 75, 0),\n",
    "    (\"../test_0_75/pod_20\", \"cpu\", \"CPU Usage\", 20, 75, 0),\n",
    "    (\"../test_0_75/pod_20\", \"memory\", \"Memory Usage\", 20, 75, 0),\n",
    "]\n",
    "\n",
    "DEPLOYMENTS = {\"HPA\": \"hpa-flask-app\", \"RL\": \"test-flask-app\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0178fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_means(base_path):\n",
    "    hpa, rl = [], []\n",
    "    for i in range(1, 21):  # Check files 1.csv to 20.csv\n",
    "        path = f\"{base_path}/{i}.csv\"\n",
    "        if not os.path.exists(path):\n",
    "            continue  # Skip missing files instead of stopping\n",
    "\n",
    "        try:\n",
    "            # InfluxDB annotated CSV: 3 annotation rows, then header at row index 3\n",
    "            df = pd.read_csv(path, header=3)\n",
    "\n",
    "            # Fallback: try reading without annotation rows (plain CSV)\n",
    "            if '_value' not in df.columns:\n",
    "                df = pd.read_csv(path)\n",
    "\n",
    "            print(f\"Loaded {path}: {len(df)} rows\")\n",
    "\n",
    "            if 'deployment' in df.columns and '_value' in df.columns:\n",
    "                means = df.groupby('deployment')['_value'].mean()\n",
    "                if DEPLOYMENTS[\"HPA\"] in means: hpa.append(means[DEPLOYMENTS[\"HPA\"]])\n",
    "                if DEPLOYMENTS[\"RL\"] in means: rl.append(means[DEPLOYMENTS[\"RL\"]])\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {path}: {e}\")\n",
    "\n",
    "    return hpa, rl\n",
    "\n",
    "def analyze_stats(hpa, rl):\n",
    "    n = min(len(hpa), len(rl))\n",
    "    if n < 3: return None  # Need at least 3 samples for Shapiro-Wilk/tests\n",
    "\n",
    "    x, y = hpa[:n], rl[:n]\n",
    "\n",
    "    # Normality check (Shapiro-Wilk)\n",
    "    # H0: Distribution is Normal. If p > 0.05, we fail to reject H0 (assume normal).\n",
    "    shapiro_hpa = stats.shapiro(x)\n",
    "    shapiro_rl = stats.shapiro(y)\n",
    "\n",
    "    is_normal = (shapiro_hpa.pvalue > 0.05) and (shapiro_rl.pvalue > 0.05)\n",
    "\n",
    "    # Statistical Test\n",
    "    diff = np.array(x) - np.array(y)\n",
    "\n",
    "    # Guard: if all differences are zero, no test is meaningful\n",
    "    if np.allclose(diff, 0):\n",
    "        return {\n",
    "            \"N\": n,\n",
    "            \"HPA Mean\": np.mean(x),\n",
    "            \"RL Mean\": np.mean(y),\n",
    "            \"Diff (%)\": 0.0,\n",
    "            \"Normality P(HPA)\": shapiro_hpa.pvalue,\n",
    "            \"Normality P(RL)\": shapiro_rl.pvalue,\n",
    "            \"P-Value\": 1.0,\n",
    "            \"Significant\": False,\n",
    "            \"Test\": \"N/A (identical values)\",\n",
    "            \"Effect Size\": 0.0\n",
    "        }\n",
    "\n",
    "    if is_normal:\n",
    "        stat, p_val = stats.ttest_rel(x, y)\n",
    "        test_name = \"Paired t-test\"\n",
    "    else:\n",
    "        try:\n",
    "            stat, p_val = stats.wilcoxon(x, y)\n",
    "            test_name = \"Wilcoxon\"\n",
    "        except ValueError as e:\n",
    "            # Wilcoxon can fail on edge cases (e.g., too few non-zero differences)\n",
    "            print(f\"  Wilcoxon failed ({e}), falling back to Paired t-test\")\n",
    "            stat, p_val = stats.ttest_rel(x, y)\n",
    "            test_name = \"Paired t-test (fallback)\"\n",
    "\n",
    "    # Effect Size (Cohen's d for paired samples)\n",
    "    std_diff = np.std(diff, ddof=1)\n",
    "    cohens_d = np.mean(diff) / std_diff if std_diff != 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"N\": n,\n",
    "        \"HPA Mean\": np.mean(x),\n",
    "        \"RL Mean\": np.mean(y),\n",
    "        \"Diff (%)\": (np.mean(y) - np.mean(x)) / np.mean(x) * 100 if np.mean(x) != 0 else np.nan,\n",
    "        \"Normality P(HPA)\": shapiro_hpa.pvalue,\n",
    "        \"Normality P(RL)\": shapiro_rl.pvalue,\n",
    "        \"P-Value\": p_val,\n",
    "        \"Significant\": p_val < 0.05,\n",
    "        \"Test\": test_name,\n",
    "        \"Effect Size\": cohens_d\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa149405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_normality_plots(hpa, rl, folder, metric_dir, label, pod):\n",
    "    # Create the directory structure: e.g., result/inferensial_test/pod_10/response_time/\n",
    "    output_dir = f\"{folder}/{metric_dir}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Saving plots to: {output_dir}/\")\n",
    "\n",
    "    # --- 1. Save INDIVIDUAL plots ---\n",
    "    # HPA Histogram\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.hist(hpa, bins='auto', alpha=0.7, color='blue', edgecolor='black', rwidth=0.85)\n",
    "    plt.title(f\"HPA Histogram - {label}\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/inferensial_histogram_{metric_dir}_hpa_{pod}_pod.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # HPA Q-Q Plot\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    stats.probplot(hpa, dist=\"norm\", plot=plt)\n",
    "    plt.title(f\"HPA Q-Q Plot - {label}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/inferensial_qq_plot_{metric_dir}_hpa_{pod}_pod.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # RL Histogram\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.hist(rl, bins='auto', alpha=0.7, color='green', edgecolor='black', rwidth=0.85)\n",
    "    plt.title(f\"RL Histogram - {label}\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/inferensial_histogram_{metric_dir}_rl_{pod}_pod.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # RL Q-Q Plot\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    stats.probplot(rl, dist=\"norm\", plot=plt)\n",
    "    plt.title(f\"RL Q-Q Plot - {label}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/inferensial_qq_plot_{metric_dir}_rl_{pod}_pod.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # --- 2. Show SUMMARY plot (Combined) ---\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    fig.suptitle(f\"Normality Analysis: {label} ({folder})\", fontsize=16)\n",
    "\n",
    "    # Plot on subplots\n",
    "    axes[0, 0].hist(hpa, bins='auto', alpha=0.7, color='blue', edgecolor='black', rwidth=0.85)\n",
    "    axes[0, 0].set_title(f\"HPA Histogram\")\n",
    "    axes[0, 0].set_ylabel(\"Frequency\")\n",
    "\n",
    "    stats.probplot(hpa, dist=\"norm\", plot=axes[0, 1])\n",
    "    axes[0, 1].set_title(f\"HPA Q-Q Plot\")\n",
    "\n",
    "    axes[1, 0].hist(rl, bins='auto', alpha=0.7, color='green', edgecolor='black', rwidth=0.85)\n",
    "    axes[1, 0].set_title(f\"RL Histogram\")\n",
    "    axes[1, 0].set_ylabel(\"Frequency\")\n",
    "\n",
    "    stats.probplot(rl, dist=\"norm\", plot=axes[1, 1])\n",
    "    axes[1, 1].set_title(f\"RL Q-Q Plot\")\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust for main title\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2200fa",
   "metadata": {},
   "source": [
    "## Prosedur Pemilihan Metode Uji Statistik\n",
    "\n",
    "Notebook ini menggunakan pendekatan sistematis untuk memilih metode uji yang sesuai:\n",
    "\n",
    "### 1. **Uji Normalitas (Shapiro-Wilk Test)**\n",
    "Langkah pertama adalah menguji apakah data mengikuti distribusi normal:\n",
    "- **Hipotesis Nol (H₀):** Data mengikuti distribusi normal\n",
    "- **Kriteria:** Jika *p*-value > 0,05 → Data dianggap normal\n",
    "- **Dilakukan untuk:** Data HPA dan data RL secara terpisah\n",
    "\n",
    "**Formula Shapiro-Wilk:**\n",
    "$$W = \\frac{\\left(\\sum_{i=1}^{n} a_i x_{(i)}\\right)^2}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}$$\n",
    "\n",
    "Dimana:\n",
    "- $x_{(i)}$ = nilai sampel yang diurutkan\n",
    "- $a_i$ = konstanta yang dihasilkan dari mean, varians, dan kovarians dari statistik order\n",
    "- $n$ = jumlah sampel\n",
    "- Nilai $W$ mendekati 1 menunjukkan data mendekati distribusi normal\n",
    "\n",
    "### 2. **Pemilihan Metode Uji**\n",
    "Berdasarkan hasil uji normalitas:\n",
    "\n",
    "#### **A. Paired t-test (Uji Parametrik)**\n",
    "**Digunakan jika:** Kedua distribusi (HPA dan RL) bersifat normal\n",
    "\n",
    "**Formula:**\n",
    "$$t = \\frac{\\bar{d}}{s_d / \\sqrt{n}}$$\n",
    "\n",
    "Dimana:\n",
    "- $\\bar{d}$ = rata-rata dari selisih berpasangan ($d_i = x_i - y_i$)\n",
    "- $s_d$ = standar deviasi dari selisih: $s_d = \\sqrt{\\frac{\\sum_{i=1}^{n}(d_i - \\bar{d})^2}{n-1}}$\n",
    "- $n$ = jumlah pasangan sampel\n",
    "- Derajat kebebasan: $df = n - 1$\n",
    "\n",
    "**Asumsi:** \n",
    "- Data berpasangan\n",
    "- Distribusi normal\n",
    "- Skala pengukuran interval/rasio\n",
    "\n",
    "**Effect Size - Cohen's *d* untuk paired samples:**\n",
    "$$d = \\frac{\\bar{d}}{s_d}$$\n",
    "\n",
    "Interpretasi:\n",
    "- $|d| < 0.2$: efek sangat kecil\n",
    "- $0.2 \\leq |d| < 0.5$: efek kecil\n",
    "- $0.5 \\leq |d| < 0.8$: efek sedang\n",
    "- $|d| \\geq 0.8$: efek besar\n",
    "\n",
    "#### **B. Wilcoxon Signed-Rank Test (Uji Non-Parametrik)**\n",
    "**Digunakan jika:** Salah satu atau kedua distribusi tidak normal\n",
    "\n",
    "**Formula:**\n",
    "$$W = \\sum_{i=1}^{n} [\\text{sgn}(x_i - y_i) \\cdot R_i]$$\n",
    "\n",
    "Langkah perhitungan:\n",
    "1. Hitung selisih: $d_i = x_i - y_i$\n",
    "2. Abaikan $d_i = 0$\n",
    "3. Urutkan $|d_i|$ dan beri rank $R_i$\n",
    "4. Kalikan rank dengan tanda dari $d_i$\n",
    "5. Jumlahkan signed ranks untuk mendapatkan statistik $W$\n",
    "\n",
    "**Asumsi:**\n",
    "- Data berpasangan\n",
    "- Tidak memerlukan distribusi normal\n",
    "- Skala pengukuran ordinal, interval, atau rasio\n",
    "- Distribusi simetris dari selisih\n",
    "\n",
    "**Effect Size - *r* untuk Wilcoxon:**\n",
    "$$r = \\frac{Z}{\\sqrt{n}}$$\n",
    "\n",
    "Dimana:\n",
    "- $Z$ = statistik normal dari Wilcoxon test\n",
    "- $n$ = jumlah pasangan sampel\n",
    "\n",
    "Atau menggunakan formula alternatif yang digunakan dalam kode ini:\n",
    "$$r = \\frac{|\\bar{d}|}{s_d}$$\n",
    "\n",
    "**Keuntungan:** Lebih robust terhadap outlier dan data tidak normal\n",
    "\n",
    "### 3. **Formula Selisih Persentase**\n",
    "$$\\text{Diff (\\%)} = \\frac{\\bar{x}_{\\text{RL}} - \\bar{x}_{\\text{HPA}}}{\\bar{x}_{\\text{HPA}}} \\times 100\\%$$\n",
    "\n",
    "Dimana:\n",
    "- $\\bar{x}_{\\text{HPA}}$ = rata-rata nilai HPA\n",
    "- $\\bar{x}_{\\text{RL}}$ = rata-rata nilai RL\n",
    "- Nilai negatif: RL lebih rendah dari HPA\n",
    "- Nilai positif: RL lebih tinggi dari HPA\n",
    "\n",
    "### 4. **Interpretasi Effect Size**\n",
    "\n",
    "| Cohen's *d* / *r* | Interpretasi |\n",
    "|-------------------|--------------|\n",
    "| < 0.2 | Sangat kecil |\n",
    "| 0.2 - 0.5 | Kecil |\n",
    "| 0.5 - 0.8 | Sedang |\n",
    "| > 0.8 | Besar |\n",
    "\n",
    "### 5. **Contoh Penerapan dalam Kode**\n",
    "```python\n",
    "# Dalam fungsi analyze_stats():\n",
    "\n",
    "# Step 1: Uji normalitas\n",
    "shapiro_hpa = stats.shapiro(x)  # Shapiro-Wilk test untuk HPA\n",
    "shapiro_rl = stats.shapiro(y)   # Shapiro-Wilk test untuk RL\n",
    "\n",
    "is_normal = (shapiro_hpa.pvalue > 0.05) and (shapiro_rl.pvalue > 0.05)\n",
    "\n",
    "# Step 2: Hitung selisih\n",
    "diff = np.array(x) - np.array(y)  # d_i = HPA_i - RL_i\n",
    "\n",
    "# Step 3: Pilih uji statistik\n",
    "if is_normal:\n",
    "    # Kedua distribusi normal → Paired t-test\n",
    "    stat, p_val = stats.ttest_rel(x, y)\n",
    "    test_name = \"Paired t-test\"\n",
    "else:\n",
    "    # Salah satu tidak normal → Wilcoxon\n",
    "    stat, p_val = stats.wilcoxon(x, y)\n",
    "    test_name = \"Wilcoxon\"\n",
    "\n",
    "# Step 4: Hitung effect size\n",
    "std_diff = np.std(diff, ddof=1)  # Standar deviasi selisih\n",
    "cohens_d = np.mean(diff) / std_diff  # Cohen's d\n",
    "```\n",
    "\n",
    "### 6. **Catatan Penting**\n",
    "- **Fallback:** Jika Wilcoxon test gagal (misal: terlalu sedikit perbedaan non-zero), sistem akan kembali menggunakan Paired t-test\n",
    "- **Signifikansi:** Hasil dianggap signifikan jika *p*-value < 0,05 (α = 5%)\n",
    "- **Visualisasi:** Q-Q plot digunakan untuk validasi visual dari hasil uji normalitas\n",
    "- **Paired samples:** Semua uji dilakukan pada data berpasangan (run yang sama untuk HPA dan RL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6de84b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_scientific(val):\n",
    "    \"\"\"Format scientific notation for LaTeX with proper spacing\"\"\"\n",
    "    if val < 0.001:\n",
    "        parts = f\"{val:.3e}\".split('e')\n",
    "        mantissa = parts[0]\n",
    "        exponent = int(parts[1])\n",
    "        return f\"${mantissa} \\\\times 10^{{{exponent}}}$\"\n",
    "    else:\n",
    "        return f\"{val:.3f}\"\n",
    "\n",
    "def format_effect_size(val, test_name):\n",
    "    \"\"\"Format effect size with appropriate label\"\"\"\n",
    "    if \"Wilcoxon\" in test_name:\n",
    "        return f\"{abs(val):.3f}\"\n",
    "    else:\n",
    "        return f\"{val:.3f}\"\n",
    "\n",
    "def generate_latex_table(results_df, metric_name, table_label, caption):\n",
    "    \"\"\"Generate LaTeX table for a specific metric\"\"\"\n",
    "\n",
    "    # Filter results for the specific metric\n",
    "    metric_data = results_df[results_df['Metric'] == metric_name]\n",
    "\n",
    "    # Get data for pod_10 and pod_20\n",
    "    pod_10 = metric_data[metric_data['Scenario'] == 'pod_10'].iloc[0] if len(metric_data[metric_data['Scenario'] == 'pod_10']) > 0 else None\n",
    "    pod_20 = metric_data[metric_data['Scenario'] == 'pod_20'].iloc[0] if len(metric_data[metric_data['Scenario'] == 'pod_20']) > 0 else None\n",
    "\n",
    "    latex = []\n",
    "    latex.append(\"\\\\begin{table}[H]\")\n",
    "    latex.append(\"  \\\\centering\")\n",
    "    latex.append(f\"  \\\\caption{{{caption}}}\\\\label{{{table_label}}}\")\n",
    "    latex.append(\"  \\\\begin{tabular}{lcc}\")\n",
    "    latex.append(\"    \\\\toprule\")\n",
    "    latex.append(\"    \\\\textbf{Statistik} & \\\\textbf{10 Pod} & \\\\textbf{20 Pod} \\\\\\\\\")\n",
    "    latex.append(\"    \\\\midrule\")\n",
    "\n",
    "    # N\n",
    "    n_10 = int(pod_10['N']) if pod_10 is not None else \"-\"\n",
    "    n_20 = int(pod_20['N']) if pod_20 is not None else \"-\"\n",
    "    latex.append(f\"    Jumlah sampel ($N$) & {n_10} & {n_20} \\\\\\\\\")\n",
    "\n",
    "    # HPA Mean\n",
    "    if \"Response Time\" in metric_name:\n",
    "        unit = \" (ms)\"\n",
    "        hpa_10 = f\"{pod_10['HPA Mean']:.3f}\" if pod_10 is not None else \"-\"\n",
    "        hpa_20 = f\"{pod_20['HPA Mean']:.3f}\" if pod_20 is not None else \"-\"\n",
    "    elif \"Replica\" in metric_name:\n",
    "        unit = \"\"\n",
    "        hpa_10 = f\"{pod_10['HPA Mean']:.3f}\" if pod_10 is not None else \"-\"\n",
    "        hpa_20 = f\"{pod_20['HPA Mean']:.3f}\" if pod_20 is not None else \"-\"\n",
    "    else:  # CPU or Memory\n",
    "        unit = \" (\\\\%)\"\n",
    "        hpa_10 = f\"{pod_10['HPA Mean']:.3f}\" if pod_10 is not None else \"-\"\n",
    "        hpa_20 = f\"{pod_20['HPA Mean']:.3f}\" if pod_20 is not None else \"-\"\n",
    "\n",
    "    latex.append(f\"    Rata-rata HPA{unit} & {hpa_10} & {hpa_20} \\\\\\\\\")\n",
    "\n",
    "    # RL Mean\n",
    "    rl_10 = f\"{pod_10['RL Mean']:.3f}\" if pod_10 is not None else \"-\"\n",
    "    rl_20 = f\"{pod_20['RL Mean']:.3f}\" if pod_20 is not None else \"-\"\n",
    "    latex.append(f\"    Rata-rata RL{unit} & {rl_10} & {rl_20} \\\\\\\\\")\n",
    "\n",
    "    # Diff (%)\n",
    "    diff_10 = f\"${pod_10['Diff (%)']:.3f}$\" if pod_10 is not None else \"-\"\n",
    "    diff_20 = f\"${pod_20['Diff (%)']:.3f}$\" if pod_20 is not None else \"-\"\n",
    "    latex.append(f\"    Selisih (\\\\%) & {diff_10} & {diff_20} \\\\\\\\\")\n",
    "\n",
    "    latex.append(\"    \\\\midrule\")\n",
    "\n",
    "    # Normality P-values\n",
    "    norm_hpa_10 = f\"{pod_10['Normality P(HPA)']:.3f}\" if pod_10 is not None else \"-\"\n",
    "    norm_hpa_20 = f\"{pod_20['Normality P(HPA)']:.3f}\" if pod_20 is not None else \"-\"\n",
    "    latex.append(f\"    \\\\emph{{P}}-value normalitas (HPA) & {norm_hpa_10} & {norm_hpa_20} \\\\\\\\\")\n",
    "\n",
    "    norm_rl_10 = f\"{pod_10['Normality P(RL)']:.3f}\" if pod_10 is not None else \"-\"\n",
    "    norm_rl_20 = f\"{pod_20['Normality P(RL)']:.3f}\" if pod_20 is not None else \"-\"\n",
    "    latex.append(f\"    \\\\emph{{P}}-value normalitas (RL) & {norm_rl_10} & {norm_rl_20} \\\\\\\\\")\n",
    "\n",
    "    # Test used\n",
    "    test_10 = f\"\\\\emph{{{pod_10['Test']}}}\" if pod_10 is not None else \"-\"\n",
    "    test_20 = f\"\\\\emph{{{pod_20['Test']}}}\" if pod_20 is not None else \"-\"\n",
    "    latex.append(f\"    Uji yang digunakan & {test_10} & {test_20} \\\\\\\\\")\n",
    "\n",
    "    # P-value\n",
    "    pval_10 = format_scientific(pod_10['P-Value']) if pod_10 is not None else \"-\"\n",
    "    pval_20 = format_scientific(pod_20['P-Value']) if pod_20 is not None else \"-\"\n",
    "    latex.append(f\"    \\\\emph{{P}}-value & {pval_10} & {pval_20} \\\\\\\\\")\n",
    "\n",
    "    # Significant\n",
    "    sig_10 = \"Ya\" if pod_10 is not None and pod_10['Significant'] else \"Tidak\"\n",
    "    sig_20 = \"Ya\" if pod_20 is not None and pod_20['Significant'] else \"Tidak\"\n",
    "    latex.append(f\"    Signifikan ($\\\\alpha = 0{{,}}05$) & {sig_10} & {sig_20} \\\\\\\\\")\n",
    "\n",
    "    # Effect Size\n",
    "    if pod_10 is not None and \"Wilcoxon\" in pod_10['Test']:\n",
    "        effect_label = \"$r$\"\n",
    "    else:\n",
    "        effect_label = \"Cohen's $d$\"\n",
    "\n",
    "    effect_10 = format_effect_size(pod_10['Effect Size'], pod_10['Test']) if pod_10 is not None else \"-\"\n",
    "    effect_20 = format_effect_size(pod_20['Effect Size'], pod_20['Test']) if pod_20 is not None else \"-\"\n",
    "    latex.append(f\"    \\\\emph{{Effect size}} ({effect_label}) & {effect_10} & {effect_20} \\\\\\\\\")\n",
    "\n",
    "    latex.append(\"    \\\\bottomrule\")\n",
    "    latex.append(\"  \\\\end{tabular}\")\n",
    "    latex.append(\"\\\\end{table}\")\n",
    "\n",
    "    return \"\\n\".join(latex)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70893ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = []\n",
    "results = []\n",
    "for folder, metric_dir, label, pod, step, delay in METRICS:\n",
    "    # METRICS use relative paths like \"../test_3_0/pod_10\"; normalize to data/ directory\n",
    "    normalized_folder = folder.replace(\"../\", \"\").lstrip(\"/\")\n",
    "    # data path is under DATA_DIR (PROJECT_ROOT/data/...)\n",
    "    path = os.path.join(DATA_DIR, normalized_folder, metric_dir)\n",
    "    if not os.path.exists(path):\n",
    "        # If data is missing, warn and skip — do NOT create empty directories which mask missing data\n",
    "        print(f\"Warning: data path not found, skipping: {path}\")\n",
    "        continue\n",
    "\n",
    "    hpa_vals, rl_vals = get_run_means(path)\n",
    "\n",
    "    # Validate data length before plotting\n",
    "    if len(hpa_vals) >= 3 and len(rl_vals) >= 3:\n",
    "        # Pass folder and metric_dir to save in the correct path}\"\n",
    "        save_normality_plots(hpa_vals, rl_vals, f\"{CHARTS_DIR}/test_{delay}_{step}/pod_{pod}\", metric_dir, label, pod)\n",
    "\n",
    "    stats_res = analyze_stats(hpa_vals, rl_vals)\n",
    "\n",
    "    if stats_res:\n",
    "        # Normalize scenario to a short label so table generation can filter by 'pod_10' / 'pod_20'\n",
    "        stats_res.update({\"Scenario\": f\"pod_{pod}\", \"Metric\": label})\n",
    "        results.append(stats_res)\n",
    "    print(\"\")\n",
    "\n",
    "if results:\n",
    "    columns = [\"Scenario\", \"Metric\", \"N\", \"HPA Mean\", \"RL Mean\", \"Diff (%)\",\n",
    "               \"Normality P(HPA)\", \"Normality P(RL)\",\n",
    "               \"P-Value\", \"Significant\", \"Test\", \"Effect Size\"]\n",
    "    print(pd.DataFrame(results)[columns].to_string())\n",
    "else:\n",
    "    print(\"No valid data found for analysis.\")\n",
    "\n",
    "# Prepare output tables only if we have results\n",
    "os.makedirs(\"tables\", exist_ok=True)\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "if results_df.empty:\n",
    "    print(\"No results available — skipping LaTeX table generation.\")\n",
    "else:\n",
    "    # Generate tables for each metric\n",
    "    tables = [\n",
    "        (\"Response Time (ms)\", \"tab:inferensial-waktu-respon\", \"Hasil Uji Inferensial Waktu Respons\", \"inferensial_waktu_respon.tex\"),\n",
    "        (\"Replica Count\", \"tab:inferensial-jumlah-replika\", \"Hasil Uji Inferensial Jumlah Replika\", \"inferensial_jumlah_replika.tex\"),\n",
    "        (\"CPU Usage\", \"tab:inferensial-penggunaan-cpu\", \"Hasil Uji Inferensial Penggunaan CPU\", \"inferensial_penggunaan_cpu.tex\"),\n",
    "        (\"Memory Usage\", \"tab:inferensial-penggunaan-memori\", \"Hasil Uji Inferensial Penggunaan Memori\", \"inferensial_penggunaan_memori.tex\"),\n",
    "    ]\n",
    "\n",
    "    for metric_name, label, caption, filename in tables:\n",
    "        # Safety: ensure required column exists\n",
    "        if 'Metric' not in results_df.columns:\n",
    "            print(f\"Skipping table {filename}: 'Metric' column missing in results dataframe\")\n",
    "            continue\n",
    "\n",
    "        latex_table = generate_latex_table(results_df, metric_name, label, caption)\n",
    "\n",
    "        # Save to file\n",
    "        with open(f\"tables/{filename}\", \"w\") as f:\n",
    "            f.write(latex_table)\n",
    "\n",
    "        print(f\"Saved: tables/{filename}\")\n",
    "        print(latex_table)\n",
    "        print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e615c93a",
   "metadata": {},
   "source": [
    "## Cara Kerja Q-Q Plot (Quantile-Quantile Plot)\n",
    "\n",
    "Q-Q plot adalah metode grafis untuk menguji apakah data mengikuti distribusi tertentu (dalam kasus ini: distribusi normal).\n",
    "\n",
    "### **Konsep Dasar**\n",
    "Q-Q plot membandingkan **quantile dari data sampel** dengan **quantile teoritis dari distribusi normal**. Jika data mengikuti distribusi normal, titik-titik akan berada di sepanjang garis diagonal.\n",
    "\n",
    "### **Langkah Pembuatan Q-Q Plot**\n",
    "\n",
    "#### **1. Urutkan Data**\n",
    "Misalkan kita memiliki $n$ observasi: $x_1, x_2, ..., x_n$\n",
    "\n",
    "Urutkan data menjadi: $x_{(1)} \\leq x_{(2)} \\leq ... \\leq x_{(n)}$\n",
    "\n",
    "#### **2. Hitung Sample Quantiles (Sumbu Y)**\n",
    "Sample quantiles adalah nilai data yang sudah diurutkan: $x_{(i)}$\n",
    "\n",
    "#### **3. Hitung Theoretical Quantiles (Sumbu X)**\n",
    "Untuk setiap data ke-$i$, hitung posisi kuantil teoritis:\n",
    "\n",
    "$$p_i = \\frac{i - 0.5}{n}$$\n",
    "\n",
    "Atau menggunakan formula alternatif:\n",
    "$$p_i = \\frac{i - 0.375}{n + 0.25}$$\n",
    "\n",
    "Kemudian hitung theoretical quantile dari distribusi normal standar:\n",
    "$$q_i = \\Phi^{-1}(p_i)$$\n",
    "\n",
    "Dimana:\n",
    "- $\\Phi^{-1}$ = inverse cumulative distribution function (CDF) dari distribusi normal standar\n",
    "- $p_i$ = probabilitas kumulatif untuk data ke-$i$\n",
    "- $q_i$ = theoretical quantile (nilai z-score)\n",
    "\n",
    "#### **4. Plot Titik-Titik**\n",
    "Buat scatter plot dengan:\n",
    "- **Sumbu X:** Theoretical quantiles ($q_i$)\n",
    "- **Sumbu Y:** Sample quantiles ($x_{(i)}$)\n",
    "\n",
    "#### **5. Tambahkan Garis Referensi**\n",
    "Garis diagonal merah dihitung dengan:\n",
    "$$y = \\mu + \\sigma \\cdot x$$\n",
    "\n",
    "Dimana:\n",
    "- $\\mu$ = mean dari sampel data\n",
    "- $\\sigma$ = standar deviasi dari sampel data\n",
    "- $x$ = theoretical quantile\n",
    "\n",
    "### **Formula Lengkap untuk Scipy**\n",
    "\n",
    "Dalam kode Python menggunakan `scipy.stats.probplot()`:\n",
    "\n",
    "```python\n",
    "stats.probplot(data, dist=\"norm\", plot=plt)\n",
    "```\n",
    "\n",
    "Proses internal:\n",
    "1. **Urutkan data:** $x_{(1)}, x_{(2)}, ..., x_{(n)}$\n",
    "2. **Hitung plotting positions:**\n",
    "   $$p_i = \\frac{i - 0.375}{n + 0.25}$$\n",
    "3. **Hitung theoretical quantiles:**\n",
    "   $$q_i = \\Phi^{-1}(p_i) = \\text{norm.ppf}(p_i)$$\n",
    "4. **Plot:** $(q_i, x_{(i)})$ untuk $i = 1, 2, ..., n$\n",
    "5. **Fit line:** $y = a + b \\cdot x$ menggunakan least squares\n",
    "\n",
    "### **Interpretasi Visual**\n",
    "\n",
    "| Pattern | Arti |\n",
    "|---------|------|\n",
    "| **Titik di sepanjang garis** | Data normal ✓ |\n",
    "| **Kurva 'S'** | Data memiliki tails yang lebih ringan/berat dari normal |\n",
    "| **Kurva cekung** | Right-skewed (ekor ke kanan) |\n",
    "| **Kurva cembung** | Left-skewed (ekor ke kiri) |\n",
    "| **Titik terpisah di ujung** | Outliers |\n",
    "\n",
    "### **Contoh Perhitungan Manual**\n",
    "\n",
    "Misalkan kita punya data: [2.1, 2.5, 2.7, 4.5, 4.7]\n",
    "\n",
    "**Step 1:** Data sudah urut ✓\n",
    "\n",
    "**Step 2:** Sample quantiles = [2.1, 2.5, 2.7, 4.5, 4.7]\n",
    "\n",
    "**Step 3:** Hitung theoretical quantiles untuk $n=5$:\n",
    "- $p_1 = \\frac{1-0.375}{5+0.25} = 0.119$ → $q_1 = \\Phi^{-1}(0.119) = -1.18$\n",
    "- $p_2 = \\frac{2-0.375}{5+0.25} = 0.310$ → $q_2 = \\Phi^{-1}(0.310) = -0.50$\n",
    "- $p_3 = \\frac{3-0.375}{5+0.25} = 0.500$ → $q_3 = \\Phi^{-1}(0.500) = 0.00$\n",
    "- $p_4 = \\frac{4-0.375}{5+0.25} = 0.690$ → $q_4 = \\Phi^{-1}(0.690) = 0.50$\n",
    "- $p_5 = \\frac{5-0.375}{5+0.25} = 0.881$ → $q_5 = \\Phi^{-1}(0.881) = 1.18$\n",
    "\n",
    "**Step 4:** Plot pairs: $(-1.18, 2.1)$, $(-0.50, 2.5)$, $(0.00, 2.7)$, $(0.50, 4.5)$, $(1.18, 4.7)$\n",
    "\n",
    "**Step 5:** Fit line melalui titik-titik ini\n",
    "\n",
    "### **Hubungan dengan Shapiro-Wilk Test**\n",
    "\n",
    "Q-Q plot adalah **visualisasi**, sedangkan Shapiro-Wilk adalah **uji statistik**:\n",
    "- **Q-Q plot:** Memberikan insight visual tentang jenis deviasi dari normalitas\n",
    "- **Shapiro-Wilk:** Memberikan nilai *p* untuk keputusan statistik (reject/fail to reject H₀)\n",
    "\n",
    "**Best Practice:** Gunakan keduanya bersama-sama untuk analisis lengkap!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d6d66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh Implementasi Manual Q-Q Plot\n",
    "# Untuk memahami cara kerjanya secara detail\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Data contoh\n",
    "data = np.array([2.1, 2.5, 2.7, 4.5, 4.7, 2.3, 3.1, 3.8, 4.2])\n",
    "n = len(data)\n",
    "\n",
    "# Step 1: Urutkan data\n",
    "sorted_data = np.sort(data)\n",
    "print(\"Data terurut:\", sorted_data)\n",
    "\n",
    "# Step 2: Hitung theoretical quantiles\n",
    "# Menggunakan formula: p_i = (i - 0.375) / (n + 0.25)\n",
    "i = np.arange(1, n + 1)\n",
    "p_i = (i - 0.375) / (n + 0.25)\n",
    "theoretical_quantiles = stats.norm.ppf(p_i)  # Inverse CDF dari normal standar\n",
    "\n",
    "print(\"\\nPlotting positions (p_i):\", p_i)\n",
    "print(\"Theoretical quantiles (z-scores):\", theoretical_quantiles)\n",
    "\n",
    "# Step 3: Plot manual\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Manual Q-Q Plot\n",
    "axes[0].scatter(theoretical_quantiles, sorted_data, color='blue', s=50, alpha=0.7)\n",
    "\n",
    "# Fit line: y = a + b*x\n",
    "slope, intercept = np.polyfit(theoretical_quantiles, sorted_data, 1)\n",
    "line_x = np.array([theoretical_quantiles.min(), theoretical_quantiles.max()])\n",
    "line_y = slope * line_x + intercept\n",
    "axes[0].plot(line_x, line_y, 'r-', linewidth=2, label=f'y = {intercept:.2f} + {slope:.2f}x')\n",
    "\n",
    "axes[0].set_xlabel('Theoretical Quantiles (z-scores)')\n",
    "axes[0].set_ylabel('Sample Quantiles (ordered values)')\n",
    "axes[0].set_title('Manual Q-Q Plot')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].legend()\n",
    "\n",
    "# Scipy Q-Q Plot untuk perbandingan\n",
    "stats.probplot(data, dist=\"norm\", plot=axes[1])\n",
    "axes[1].set_title('Scipy Q-Q Plot (untuk verifikasi)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nGaris fit: y = {intercept:.3f} + {slope:.3f}x\")\n",
    "print(f\"Dimana: intercept ≈ mean = {np.mean(data):.3f}\")\n",
    "print(f\"        slope ≈ std = {np.std(data, ddof=1):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca61735",
   "metadata": {},
   "source": [
    "### Penjelasan Output Contoh di Atas:\n",
    "\n",
    "**1. Data Terurut:**\n",
    "- Data asli diurutkan dari terkecil ke terbesar\n",
    "- Ini menjadi **sample quantiles** (sumbu Y)\n",
    "\n",
    "**2. Plotting Positions (p_i):**\n",
    "- Probabilitas kumulatif untuk setiap titik data\n",
    "- Dihitung dengan: $p_i = \\frac{i - 0.375}{n + 0.25}$\n",
    "- Contoh: untuk data pertama ($i=1$, $n=9$): $p_1 = \\frac{1-0.375}{9+0.25} = 0.068$\n",
    "\n",
    "**3. Theoretical Quantiles (z-scores):**\n",
    "- Inverse CDF dari distribusi normal standar: $\\Phi^{-1}(p_i)$\n",
    "- Ini adalah **sumbu X** pada Q-Q plot\n",
    "- Contoh: $\\Phi^{-1}(0.068) = -1.494$ (nilai z-score)\n",
    "- Nilai tengah ($p=0.5$) menghasilkan $z=0$ (median distribusi normal)\n",
    "\n",
    "**4. Garis Fit:**\n",
    "- Persamaan: $y = 3.322 + 1.029x$\n",
    "- **Intercept (3.322)** ≈ mean dari data\n",
    "- **Slope (1.029)** ≈ standar deviasi dari data\n",
    "- Jika data normal sempurna: titik-titik akan berada **tepat** di garis ini\n",
    "\n",
    "**5. Interpretasi:**\n",
    "- Titik-titik di grafik manual mendekati garis merah → data mendekati normal\n",
    "- Kedua grafik (manual vs scipy) identik → verifikasi bahwa implementasi benar\n",
    "- Deviasi kecil dari garis adalah normal untuk sampel kecil ($n=9$)\n",
    "\n",
    "**Kesimpulan:** Q-Q plot mengubah data empiris menjadi sistem koordinat yang memungkinkan kita membandingkan dengan distribusi teoritis secara visual!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96c4c7a",
   "metadata": {},
   "source": [
    "### How to Read the Normality Plots\n",
    "**1. Q-Q Plot (Right Side) - The Main Indicator**\n",
    "*   **Normal:** The blue dots follow the red diagonal line.\n",
    "*   **Not Normal:** The dots curve away (like a banana or 'S' shape) or are scattered far from the line.\n",
    "\n",
    "**2. Histogram (Left Side) - The Shape**\n",
    "*   **Normal:** Looks like a \"Bell Curve\" (tall in middle, short on ends).\n",
    "*   **Note:** With small data samples (N < 20), histograms often look \"blocky\" or messy. **Trust the Q-Q Plot more.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cab4368",
   "metadata": {},
   "source": [
    "## LaTeX Tables Generated\n",
    "\n",
    "The inferential test results have been converted to LaTeX table format and saved in the `tables/` directory:\n",
    "\n",
    "1. **[tables/response_time.tex](tables/response_time.tex)** - Hasil Uji Inferensial Waktu Respons\n",
    "2. **[tables/memory.tex](tables/memory.tex)** - Hasil Uji Inferensial Penggunaan Memori  \n",
    "3. **[tables/cpu.tex](tables/cpu.tex)** - Hasil Uji Inferensial Penggunaan CPU\n",
    "4. **[tables/replica.tex](tables/replica.tex)** - Hasil Uji Inferensial Jumlah Replika\n",
    "\n",
    "Each table includes:\n",
    "- Sample size (N)\n",
    "- Mean values for HPA and RL\n",
    "- Percentage difference\n",
    "- Normality test p-values\n",
    "- Statistical test used (Paired t-test or Wilcoxon)\n",
    "- P-value with scientific notation where appropriate\n",
    "- Significance indicator\n",
    "- Effect size (Cohen's d or r depending on test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
