{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5be620c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gym\n",
    "import os\n",
    "import random\n",
    "from typing import Any\n",
    "\n",
    "# helpers\n",
    "import numpy as np\n",
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Box, Dict, Discrete, MultiBinary, MultiDiscrete, Tuple\n",
    "\n",
    "# Stable-baseline\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "# from environment import KubernetesEnv\n",
    "\n",
    "# Custom\n",
    "from typing import Optional\n",
    "from database.influxdb import InfluxDB\n",
    "import logging\n",
    "from kubernetes import client, config\n",
    "from utils import setup_logger\n",
    "from prometheus_api_client import PrometheusConnect\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4f3dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger, log_dir = setup_logger(\n",
    "    \"kubernetes_agent\", log_level=os.getenv(\"LOG_LEVEL\", \"INFO\"), log_to_file=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353220fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_pods_ready(\n",
    "    prometheus: PrometheusConnect,\n",
    "    namespace: str,\n",
    "    deployment_name: str,\n",
    "    timeout: int,\n",
    "    wait_time: int,\n",
    "    logger: logging.Logger,\n",
    "):\n",
    "    start_time = time.time()\n",
    "\n",
    "    scope_ready = f\"\"\"\n",
    "        (kube_pod_status_ready{{namespace=\"{namespace}\", condition=\"true\"}} == 1)\n",
    "        and on(pod)\n",
    "        (\n",
    "          label_replace(\n",
    "            kube_pod_owner{{namespace=\"{namespace}\", owner_kind=\"ReplicaSet\"}},\n",
    "            \"replicaset\", \"$1\", \"owner_name\", \"(.*)\"\n",
    "          )\n",
    "          * on(namespace, replicaset) group_left(owner_name)\n",
    "            kube_replicaset_owner{{\n",
    "              namespace=\"{namespace}\", owner_kind=\"Deployment\", owner_name=\"{deployment_name}\"\n",
    "            }}\n",
    "        )\n",
    "    \"\"\"  # noqa: E501\n",
    "    q_desired = f\"\"\"\n",
    "    scalar(\n",
    "      sum(\n",
    "        kube_deployment_spec_replicas{{namespace=\"{namespace}\",\n",
    "        deployment=\"{deployment_name}\"}}\n",
    "      )\n",
    "    )\n",
    "    \"\"\"\n",
    "    q_ready = f\"\"\"\n",
    "      scalar(sum({scope_ready}))\n",
    "    \"\"\"\n",
    "\n",
    "    while time.time() - start_time < timeout:\n",
    "        desired_result = prometheus.custom_query(q_desired)\n",
    "        desired = desired_result[1]\n",
    "        ready_result = prometheus.custom_query(query=q_ready)\n",
    "        ready = ready_result[1]\n",
    "        if ready == desired:\n",
    "            time.sleep(wait_time)\n",
    "            return True, desired, ready\n",
    "        logger.debug(\n",
    "            f\"Waiting for pods to be ready: {ready}/{desired}\"\n",
    "        )\n",
    "        time.sleep(1)\n",
    "    time.sleep(wait_time)\n",
    "    return False, desired, ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba23d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _metrics_query(\n",
    "    namespace: str,\n",
    "    deployment_name: str,\n",
    "    interval: int = 15,\n",
    "    desired_replicas: int | None = None,\n",
    "    quantile: float = 0.90,\n",
    "    endpoints_method: list[tuple[str, str]] = ((\"/\", \"GET\"), (\"/docs\", \"GET\")),\n",
    ") -> tuple[str, str, str, str, str]:\n",
    "    \"\"\"\n",
    "    Build pod-scoped queries and cap to the youngest desired pods.\n",
    "\n",
    "    We use topk on pod start time to keep only the newest N pods (desired replicas),\n",
    "    so older pods that are still Ready after a scale-down do not contribute.\n",
    "    \"\"\"\n",
    "    # Default to a reasonable cap if desired_replicas is None\n",
    "    pod_window = max(1, desired_replicas or 50)\n",
    "\n",
    "    pod_filter = f\"\"\"\n",
    "        topk({pod_window},\n",
    "          kube_pod_start_time{{\n",
    "            namespace=\"{namespace}\",\n",
    "            pod=~\"{deployment_name}-.*\"\n",
    "          }}\n",
    "          * on(pod) group_left()\n",
    "            (kube_pod_status_ready{{\n",
    "                namespace=\"{namespace}\",\n",
    "                pod=~\"{deployment_name}-.*\",\n",
    "                condition=\"true\"\n",
    "            }} == 1)\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    cpu_query = f\"\"\"\n",
    "        sum by (pod) (\n",
    "            rate(container_cpu_usage_seconds_total{{\n",
    "                namespace=\"{namespace}\",\n",
    "                pod=~\"{deployment_name}-.*\",\n",
    "                container!=\"\",\n",
    "                container!=\"POD\"\n",
    "            }}[{interval}s])\n",
    "        )\n",
    "        * on(pod) group_left() {pod_filter}\n",
    "        \"\"\"\n",
    "\n",
    "    memory_query = f\"\"\"\n",
    "        sum by (pod) (\n",
    "            container_memory_working_set_bytes{{\n",
    "                namespace=\"{namespace}\",\n",
    "                pod=~\"{deployment_name}-.*\",\n",
    "                container!=\"\",\n",
    "                container!=\"POD\"\n",
    "            }}\n",
    "        )\n",
    "        * on(pod) group_left() {pod_filter}\n",
    "        \"\"\"\n",
    "\n",
    "    cpu_limits_query = f\"\"\"\n",
    "        sum by (pod) (\n",
    "            kube_pod_container_resource_limits{{\n",
    "                namespace=\"{namespace}\",\n",
    "                pod=~\"{deployment_name}-.*\",\n",
    "                resource=\"cpu\",\n",
    "                unit=\"core\"\n",
    "            }}\n",
    "        )\n",
    "        * on(pod) group_left() {pod_filter}\n",
    "        \"\"\"\n",
    "\n",
    "    # Query for memory limits\n",
    "    memory_limits_query = f\"\"\"\n",
    "        sum by (pod) (\n",
    "            kube_pod_container_resource_limits{{\n",
    "                namespace=\"{namespace}\",\n",
    "                pod=~\"{deployment_name}-.*\",\n",
    "                resource=\"memory\",\n",
    "                unit=\"byte\"\n",
    "            }}\n",
    "        )\n",
    "        * on(pod) group_left() {pod_filter}\n",
    "        \"\"\"\n",
    "\n",
    "    response_time_query = []\n",
    "    for endpoint, method in endpoints_method:\n",
    "        response_time_query.append(f\"\"\"\n",
    "                1000 *\n",
    "                histogram_quantile(\n",
    "                {quantile},\n",
    "                sum by (le) (\n",
    "                    rate(http_request_duration_seconds_bucket{{\n",
    "                    namespace=\"{namespace}\",\n",
    "                    pod=~\"{deployment_name}-.*\",\n",
    "                    method=\"{method}\",\n",
    "                    path=\"{endpoint}\"\n",
    "                    }}[{interval}s])\n",
    "                )\n",
    "                )\n",
    "            \"\"\"\n",
    "        )\n",
    "    return (\n",
    "        cpu_query,\n",
    "        memory_query,\n",
    "        cpu_limits_query,\n",
    "        memory_limits_query,\n",
    "        response_time_query,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98efa36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_metrics(cpu_usage, memory_usage, cpu_limits, memory_limits, response_times, max_response_time):\n",
    "    cpu_percentages = []\n",
    "    memory_percentages = []\n",
    "\n",
    "    cpu_limits_by_pod = {}\n",
    "    memory_limits_by_pod = {}\n",
    "    for item in cpu_limits:\n",
    "        pod = item[\"metric\"][\"pod\"]\n",
    "        limit = float(item[\"value\"][1])\n",
    "        cpu_limits_by_pod[pod] = limit\n",
    "\n",
    "    for item in memory_limits:\n",
    "        pod = item[\"metric\"][\"pod\"]\n",
    "        limit = float(item[\"value\"][1])\n",
    "        memory_limits_by_pod[pod] = limit\n",
    "\n",
    "    for result in cpu_usage:\n",
    "        pod_name = result[\"metric\"].get(\"pod\")\n",
    "        limit = float(cpu_limits_by_pod.get(pod_name))\n",
    "        rate_cores = float(result[\"value\"][1])\n",
    "        cpu_percentage = (rate_cores / limit) * 100\n",
    "        cpu_percentages.append(cpu_percentage)\n",
    "\n",
    "    for result in memory_usage:\n",
    "        pod_name = result[\"metric\"].get(\"pod\")\n",
    "        limit = float(memory_limits_by_pod.get(pod_name))\n",
    "        usage_bytes = float(result[\"value\"][1])\n",
    "        memory_percentage = (usage_bytes / limit) * 100\n",
    "        memory_percentages.append(memory_percentage)\n",
    "\n",
    "    response_time = np.mean(response_times) if response_times else 0.0\n",
    "    response_time_percentage = (response_time / max_response_time) * 100.0\n",
    "    response_time_percentage = min(response_time_percentage, 1000.0)\n",
    "\n",
    "    return np.mean(cpu_percentages), np.mean(memory_percentages), response_time_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e35dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(\n",
    "    prometheus: PrometheusConnect,\n",
    "    namespace: str,\n",
    "    deployment_name: str,\n",
    "    interval: int,\n",
    "    replica: int,\n",
    "    max_response_time: float,\n",
    "):\n",
    "    (\n",
    "        cpu_query,\n",
    "        memory_query,\n",
    "        cpu_limits_query,\n",
    "        memory_limits_query,\n",
    "        response_time_query,\n",
    "    )= _metrics_query(\n",
    "        namespace,\n",
    "        deployment_name,\n",
    "        interval=interval,\n",
    "        desired_replicas=replica,\n",
    "    )\n",
    "    cpu_usage_results = prometheus.custom_query(cpu_query)\n",
    "    memory_usage_results = prometheus.custom_query(memory_query)\n",
    "    cpu_limits_results = prometheus.custom_query(cpu_limits_query)\n",
    "    memory_limits_results = prometheus.custom_query(memory_limits_query)\n",
    "\n",
    "    response_time_results = []\n",
    "    for query in response_time_query:\n",
    "        response = prometheus.custom_query(query)\n",
    "        if not response:\n",
    "            response_time_results.append(0.0)\n",
    "            continue\n",
    "\n",
    "        response_time_results.append(float(response[0][\"value\"][1]))\n",
    "\n",
    "    cpu_percentages, memory_percentages, response_time_percentage = process_metrics(\n",
    "        cpu_usage_results,\n",
    "        memory_usage_results,\n",
    "        cpu_limits_results,\n",
    "        memory_limits_results,\n",
    "        response_time_results,\n",
    "        max_response_time,\n",
    "    )\n",
    "\n",
    "    return cpu_percentages, memory_percentages, response_time_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e706895",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KubernetesEnv(Env):\n",
    "    def __init__(\n",
    "        self,\n",
    "        min_replicas: int,\n",
    "        max_replicas: int,\n",
    "        iteration: int,\n",
    "        namespace: str,\n",
    "        deployment_name: str,\n",
    "        min_cpu: float,\n",
    "        min_memory: float,\n",
    "        max_cpu: float,\n",
    "        max_memory: float,\n",
    "        max_response_time: float,\n",
    "        timeout: int,\n",
    "        wait_time: int,\n",
    "        logger: Optional[logging.Logger],\n",
    "        influxdb: Optional[InfluxDB],\n",
    "        prometheus_url: str,\n",
    "        metrics_interval: int,\n",
    "        metrics_quantile: float,\n",
    "        max_scaling_retries: int,\n",
    "        weight_response_time: float,\n",
    "        weight_cost: float,\n",
    "        metrics_endpoints_method: list[tuple[str, str]] = (\n",
    "            (\"/cpu\", \"GET\"),\n",
    "            (\"/memory\", \"GET\"),\n",
    "        ),\n",
    "    ):\n",
    "        config.load_kube_config()\n",
    "        self.api = client.AppsV1Api()\n",
    "        self.namespace = namespace\n",
    "        self.deployment_name = deployment_name\n",
    "        self.prometheus = PrometheusConnect(\n",
    "            url=prometheus_url,\n",
    "            disable_ssl=True,\n",
    "        )\n",
    "        self.timeout = timeout\n",
    "        self.wait_time = wait_time\n",
    "        self.metrics_interval = metrics_interval\n",
    "        self.metrics_quantile = metrics_quantile\n",
    "        self.metrics_endpoints_method = metrics_endpoints_method\n",
    "        self.logger = logger\n",
    "        self.action_space = Discrete(100)\n",
    "        self.observation_space = Box(\n",
    "            low=np.array([0.0, 0.0, 0.0, -2.0, -2.0, 0.0], dtype=np.float32),\n",
    "            high=np.array([1.0, 1.0, 1.0, 2.0, 2.0, 3.0], dtype=np.float32),\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "        self.iteration = iteration\n",
    "        self.iteration_init = iteration\n",
    "        self.min_replicas: int = min_replicas\n",
    "        self.max_replicas: int = max_replicas\n",
    "        self.range_replicas: int = max(1, self.max_replicas - self.min_replicas)\n",
    "        self.max_response_time: float = max_response_time\n",
    "        self.min_cpu: float = min_cpu\n",
    "        self.min_memory: float = min_memory\n",
    "        self.max_cpu: float = max_cpu\n",
    "        self.max_memory: float = max_memory\n",
    "        self.influxdb = influxdb\n",
    "        self.max_scaling_retries = max_scaling_retries\n",
    "\n",
    "        self.weight_response_time = weight_response_time\n",
    "        self.weight_cost = weight_cost\n",
    "\n",
    "        # Calculate max_response_penalty dynamically to ensure reward range [-1, 1]\n",
    "        # max penalty needed = 2.0 (so 1.0 - 2.0 = -1.0)\n",
    "        # When RT is bad, cost_weight_multiplier = 0, so only RT penalty applies\n",
    "        # weight_response_time * max_response_penalty = 2.0\n",
    "        self.max_response_penalty = 2.0 / self.weight_response_time\n",
    "\n",
    "        self.observations = np.array(\n",
    "            [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "        self.last_reward = 0.0\n",
    "\n",
    "    def step(self, action: int):\n",
    "        self.iteration -= 1\n",
    "        replica = int(action * self.range_replicas // 100 + self.min_replicas)\n",
    "\n",
    "        cpu, memory, response_time = self.scale(replica)\n",
    "\n",
    "\n",
    "        cpu_relative, memory_relative, cpu_distance, memory_distance = self.calculate_distance(cpu, memory)\n",
    "\n",
    "        reward = self.calculate_reward(action=action, response_time=response_time)\n",
    "        self.last_reward = reward\n",
    "\n",
    "        self.observations = self.observation(action=action, response_time=response_time, cpu_relative=cpu_relative, memory_relative=memory_relative, cpu_distance=cpu_distance, memory_distance=memory_distance)\n",
    "\n",
    "\n",
    "        if self.iteration <= 0:\n",
    "            terminated = True\n",
    "            truncated = True\n",
    "        else:\n",
    "            terminated = False\n",
    "            truncated = False\n",
    "\n",
    "        info = {\n",
    "            \"cpu\": cpu,\n",
    "            \"memory\": memory,\n",
    "            \"response_time\": response_time,\n",
    "            \"replicas\": replica,\n",
    "            \"action\": action,\n",
    "            \"cpu_relative\": cpu_relative,\n",
    "            \"memory_relative\": memory_relative,\n",
    "            \"cpu_distance\": cpu_distance,\n",
    "            \"memory_distance\": memory_distance,\n",
    "        }\n",
    "        if self.influxdb :\n",
    "            self.influxdb.write_point(\n",
    "                measurement=\"autoscaling_metrics\",\n",
    "                tags={\n",
    "                    \"namespace\": self.namespace,\n",
    "                    \"deployment\": self.deployment_name,\n",
    "                },\n",
    "                fields={**info},\n",
    "            )\n",
    "\n",
    "        return self.observations, reward, terminated, truncated, info\n",
    "\n",
    "    def scale(self, replica: int) -> None:\n",
    "        attempt = 0\n",
    "        while attempt < self.max_scaling_retries:\n",
    "            attempt += 1\n",
    "            delay = min(1 * (2 ** (attempt - 1)), 10)\n",
    "            try:\n",
    "                self.api.patch_namespaced_deployment_scale(\n",
    "                    name=self.deployment_name,\n",
    "                    namespace=self.namespace,\n",
    "                    body={\"spec\": {\"replicas\": replica}},\n",
    "                )\n",
    "                break\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Error scaling deployment: {e}\")\n",
    "                time.sleep(delay)\n",
    "\n",
    "        _, _, _ = wait_for_pods_ready(\n",
    "            prometheus=self.prometheus,\n",
    "            deployment_name=self.deployment_name,\n",
    "            namespace=self.namespace,\n",
    "            timeout=self.timeout,\n",
    "            wait_time=self.wait_time,\n",
    "            logger=self.logger,\n",
    "        )\n",
    "        cpu, memory, response_time = get_metrics(\n",
    "            prometheus=self.prometheus,\n",
    "            namespace=self.namespace,\n",
    "            deployment_name=self.deployment_name,\n",
    "            interval=self.metrics_interval,\n",
    "            replica=replica,\n",
    "            max_response_time=self.max_response_time,\n",
    "        )\n",
    "        return cpu, memory, response_time\n",
    "\n",
    "    def calculate_reward(self, action: int, response_time: float) -> float:\n",
    "        RESPONSE_TIME_HIGH_THRESHOLD = 80.0\n",
    "        RESPONSE_TIME_VIOLATION_THRESHOLD = 100.0\n",
    "\n",
    "        if response_time <= RESPONSE_TIME_HIGH_THRESHOLD:\n",
    "            response_time_penalty = 0.0\n",
    "        elif response_time <= RESPONSE_TIME_VIOLATION_THRESHOLD:\n",
    "            response_time_penalty = (response_time - RESPONSE_TIME_HIGH_THRESHOLD) / (\n",
    "                RESPONSE_TIME_VIOLATION_THRESHOLD - RESPONSE_TIME_HIGH_THRESHOLD\n",
    "            )\n",
    "        else:\n",
    "            over = (\n",
    "                response_time - RESPONSE_TIME_VIOLATION_THRESHOLD\n",
    "            ) / RESPONSE_TIME_VIOLATION_THRESHOLD\n",
    "            response_time_penalty = 1.0 + over\n",
    "\n",
    "        response_time_penalty = max(0.0, min(response_time_penalty, self.max_response_penalty))\n",
    "\n",
    "        cost_penalty_raw = action / 99.0\n",
    "\n",
    "        if response_time <= RESPONSE_TIME_HIGH_THRESHOLD:\n",
    "            cost_weight_multiplier = 1.0\n",
    "        elif response_time <= RESPONSE_TIME_VIOLATION_THRESHOLD:\n",
    "            cost_weight_multiplier = 1.0 - (response_time_penalty / self.max_response_penalty)\n",
    "        else:\n",
    "            cost_weight_multiplier = 0.0\n",
    "\n",
    "        effective_cost_penalty = cost_penalty_raw * cost_weight_multiplier\n",
    "\n",
    "        total_penalty = (\n",
    "            self.weight_response_time * response_time_penalty\n",
    "            + self.weight_cost * effective_cost_penalty\n",
    "        )\n",
    "        return 1.0 - total_penalty\n",
    "\n",
    "    def calculate_distance(self,cpu: float, memory: float) -> tuple[float, float]:\n",
    "        cpu_distance = (\n",
    "            (self.min_cpu - cpu) if cpu < self.min_cpu else (cpu - self.max_cpu)\n",
    "        )\n",
    "        cpu_bandwidth = self.max_cpu - self.min_cpu\n",
    "        cpu_normalized = cpu_distance / cpu_bandwidth\n",
    "        cpu_distance = cpu_normalized\n",
    "        cpu_relative = (cpu - self.min_cpu) / cpu_bandwidth\n",
    "\n",
    "\n",
    "        memory_distance = (\n",
    "            (self.min_memory - memory)\n",
    "            if memory < self.min_memory\n",
    "            else (memory - self.max_memory)\n",
    "        )\n",
    "        memory_bandwidth = self.max_memory - self.min_memory\n",
    "        memory_normalized = memory_distance / memory_bandwidth\n",
    "        memory_distance = memory_normalized\n",
    "        memory_relative = (memory - self.min_memory) / memory_bandwidth\n",
    "\n",
    "        return cpu_relative, memory_relative, cpu_distance, memory_distance\n",
    "\n",
    "    def observation(self, action: int, response_time: float, cpu_relative: float, memory_relative: float, cpu_distance: float, memory_distance: float):\n",
    "        action = action / 99.0\n",
    "\n",
    "        cpu_relative = float(np.clip(cpu_relative, 0.0, 1.0))\n",
    "        memory_relative = float(np.clip(memory_relative, 0.0, 1.0))\n",
    "        cpu_distance = float(np.clip(cpu_distance, -2.0, 2.0))\n",
    "        memory_distance = float(np.clip(memory_distance, -2.0, 2.0))\n",
    "        response_time = float(np.clip(response_time / 100.0, 0.0, 3.0))\n",
    "\n",
    "\n",
    "        return np.array(\n",
    "            [\n",
    "                action,\n",
    "                cpu_relative,\n",
    "                memory_relative,\n",
    "                cpu_distance,\n",
    "                memory_distance,\n",
    "                response_time,\n",
    "            ],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "\n",
    "    def render(self) -> None:\n",
    "        def _color(v: float, warn: float, crit: float, reverse: bool = False) -> str:\n",
    "            GREEN, YELLOW, RED = \"\\033[32m\", \"\\033[33m\", \"\\033[31m\"\n",
    "\n",
    "            if reverse:\n",
    "                ok = v <= warn\n",
    "                mid = warn < v <= crit\n",
    "            else:\n",
    "                ok = v < warn\n",
    "                mid = warn <= v < crit\n",
    "                if v >= crit:\n",
    "                    return RED\n",
    "\n",
    "            return GREEN if ok else (YELLOW if mid else RED)\n",
    "\n",
    "        def _clamp(v: float, lo: float = 0.0, hi: float = 100.0) -> float:\n",
    "            return max(lo, min(hi, v))\n",
    "\n",
    "        def _bar(pct: float, width: int = 12) -> str:\n",
    "            pct = _clamp(pct)\n",
    "            filled = round(pct / 100 * width)\n",
    "            return \"█\" * filled + \"░\" * (width - filled)\n",
    "\n",
    "        def _fmt_pct(v: float) -> str:\n",
    "            try:\n",
    "                return f\"{float(v):6.2f}%\"\n",
    "            except Exception:\n",
    "                return f\"{v}\"\n",
    "\n",
    "        action = int(self.observations[0] * 99)\n",
    "        cpu = self.observations[1] * 100.0\n",
    "        mem = self.observations[2] * 100.0\n",
    "        cpu_distance = self.observations[3]\n",
    "        mem_distance = self.observations[4]\n",
    "        rt = self.observations[5] * 100.0\n",
    "\n",
    "        def _dist_color(dist: float) -> str:\n",
    "            GREEN, YELLOW, RED = \"\\033[32m\", \"\\033[33m\", \"\\033[31m\"\n",
    "            if -0.1 <= dist <= 0.1:\n",
    "                return GREEN\n",
    "            elif dist < -0.3 or dist > 0.5:\n",
    "                return RED\n",
    "            return YELLOW\n",
    "\n",
    "        cpu_col = _dist_color(cpu_distance)\n",
    "        mem_col = _dist_color(mem_distance)\n",
    "        rt_col = _color(rt, warn=80, crit=100)\n",
    "\n",
    "        cpu_bar = _bar(cpu)\n",
    "        mem_bar = _bar(mem)\n",
    "        rt_bar = _bar(min(rt, 200.0), width=12)\n",
    "\n",
    "        RESET = \"\\033[0m\"\n",
    "\n",
    "        # line 1\n",
    "        hdr = \"▶ \"\n",
    "        cpu_str = f\"{cpu_col}CPU {_fmt_pct(cpu)} {cpu_bar}{RESET}\"\n",
    "        mem_str = f\"{mem_col}MEM {_fmt_pct(mem)} {mem_bar}{RESET}\"\n",
    "        rt_str = f\"{rt_col}RT {rt:6.1f}% {rt_bar}{RESET}\"\n",
    "        act_str = f\"ACT {action:3d}\"\n",
    "        cpu_dist_str = f\"CPU_D {cpu_distance:+7.3f}\"\n",
    "        mem_dist_str = f\"MEM_D {mem_distance:+7.3f}\"\n",
    "        reward_str = f\"RWD {self.last_reward:+6.3f}\"\n",
    "        self.logger.info(\n",
    "            f\"{' ' * len(hdr)}| {cpu_str} | {mem_str} | {rt_str} | \"\n",
    "            f\"{cpu_dist_str} | {mem_dist_str} | {act_str} | {reward_str} |\"\n",
    "        )\n",
    "\n",
    "    def reset(\n",
    "        self,\n",
    "        *,\n",
    "        seed: int | None = None,\n",
    "        options: dict[str, Any] | None = None,\n",
    "    ):\n",
    "        self.iteration = self.iteration_init\n",
    "        action = random.randint(0, 99)\n",
    "        replica = int(action * self.range_replicas // 100 + self.min_replicas)\n",
    "\n",
    "        cpu, memory, response_time = self.scale(replica)\n",
    "\n",
    "        cpu_relative, memory_relative, cpu_distance, memory_distance = self.calculate_distance(cpu, memory)\n",
    "\n",
    "        self.observations = self.observation(action=action, response_time=response_time, cpu_relative=cpu_relative, memory_relative=memory_relative, cpu_distance=cpu_distance, memory_distance=memory_distance)\n",
    "\n",
    "        info = {\n",
    "            \"cpu\": cpu,\n",
    "            \"memory\": memory,\n",
    "            \"response_time\": response_time,\n",
    "            \"replicas\": replica,\n",
    "            \"action\": action,\n",
    "            \"cpu_relative\": cpu_relative,\n",
    "            \"memory_relative\": memory_relative,\n",
    "            \"cpu_distance\": cpu_distance,\n",
    "            \"memory_distance\": memory_distance,\n",
    "        }\n",
    "\n",
    "        return self.observations, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53faf923",
   "metadata": {},
   "outputs": [],
   "source": [
    "influxdb = InfluxDB(\n",
    "    logger=logger,\n",
    "    url=os.getenv(\"INFLUXDB_URL\", \"http://localhost:8086\"),\n",
    "    token=os.getenv(\"INFLUXDB_TOKEN\", \"my-token\"),\n",
    "    org=os.getenv(\"INFLUXDB_ORG\", \"my-org\"),\n",
    "    bucket=os.getenv(\"INFLUXDB_BUCKET\", \"my-bucket\"),\n",
    ")\n",
    "\n",
    "env = KubernetesEnv(\n",
    "    min_replicas=int(os.getenv(\"MIN_REPLICAS\")),\n",
    "    max_replicas=int(os.getenv(\"MAX_REPLICAS\")),\n",
    "    iteration=int(os.getenv(\"ITERATION\")),\n",
    "    namespace=os.getenv(\"NAMESPACE\"),\n",
    "    deployment_name=os.getenv(\"DEPLOYMENT_NAME\"),\n",
    "    min_cpu=float(os.getenv(\"MIN_CPU\")),\n",
    "    min_memory=float(os.getenv(\"MIN_MEMORY\")),\n",
    "    max_cpu=float(os.getenv(\"MAX_CPU\")),\n",
    "    max_memory=float(os.getenv(\"MAX_MEMORY\")),\n",
    "    max_response_time=float(os.getenv(\"MAX_RESPONSE_TIME\")),\n",
    "    timeout=int(os.getenv(\"TIMEOUT\")),\n",
    "    wait_time=int(os.getenv(\"WAIT_TIME\")),\n",
    "    logger=logger,\n",
    "    influxdb=influxdb,\n",
    "    prometheus_url=os.getenv(\"PROMETHEUS_URL\"),\n",
    "    metrics_endpoints_method=[(\"/\", \"GET\"), (\"/docs\", \"GET\")],\n",
    "    metrics_interval=int(os.getenv(\"METRICS_INTERVAL\")),\n",
    "    metrics_quantile=float(os.getenv(\"METRICS_QUANTILE\")),\n",
    "    max_scaling_retries=int(os.getenv(\"MAX_SCALING_RETRIES\")),\n",
    "    weight_response_time=float(os.getenv(\"WEIGHT_RESPONSE_TIME\")),\n",
    "    weight_cost=float(os.getenv(\"WEIGHT_COST\")),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c064f75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f9c0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6d5066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# episodes = 10\n",
    "# for episode in range(1, episodes+1):\n",
    "#     env.reset()\n",
    "#     terminated = False\n",
    "#     truncated = False\n",
    "#     score = 0\n",
    "\n",
    "#     while not terminated and not truncated:\n",
    "#         action = env.action_space.sample()\n",
    "#         obs, reward, terminated, truncated , info = env.step(action)\n",
    "#         env.render()\n",
    "#         score += reward\n",
    "#     print(f\"Episode: {episode}  Score {score}\")\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cabbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN(\"MlpPolicy\", env, verbose=1, tensorboard_log=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71257d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(20000, reset_num_timesteps=False, progress_bar=True)\n",
    "model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0da6b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99ed32c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/2025-12-19-21-15_offline_add_estimation.csv\")\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(df[\"response_time\"], bins=20)\n",
    "plt.xlabel(\"Action\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Action Distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05cd0e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial obs: [0.75757575 0.01387174 0.19210358 0.        ]\n",
      "✓ Normalization test passed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from offline_train import OfflineEnv\n",
    "test_env = OfflineEnv()\n",
    "test_env.data = df.reset_index(drop=True)\n",
    "obs, _ = test_env.reset()\n",
    "\n",
    "print(f\"Initial obs: {obs}\")\n",
    "assert 0 <= obs[1] <= 1, f\"CPU not normalized: {obs[1]}\"\n",
    "assert 0 <= obs[2] <= 1, f\"Memory not normalized: {obs[2]}\"\n",
    "print(\"✓ Normalization test passed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
